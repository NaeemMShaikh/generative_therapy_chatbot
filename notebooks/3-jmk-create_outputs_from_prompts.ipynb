{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jcb_create_outputs_from_prompts","provenance":[{"file_id":"1cwUPVeAcnTF9sT5EcTbZXK1_vbMnuoc6","timestamp":1585256255136}],"machine_shape":"hm","mount_file_id":"1EvclzL9xn3R7wzOcqOnZwmasDQyfK2wh","authorship_tag":"ABX9TyOXHmFOquTomZTFJFOiAFrY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ww8S1B9B88Ba","colab_type":"text"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"pZGa-D528t-s","colab_type":"code","outputId":"59615343-9d89-40f2-914b-15a88b75c74f","executionInfo":{"status":"ok","timestamp":1585424779427,"user_tz":240,"elapsed":23614,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["%tensorflow_version 1.x\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files\n","from google.colab import drive\n","from collections import Counter\n","import os\n","import numpy as np\n","import glob\n","import pandas as pd\n","from tqdm import tqdm\n","!python -m spacy download en\n","import spacy\n","nlp = spacy.load('en')\n","spacy.prefer_gpu()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"HprB-pM-9iAK","colab_type":"text"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"ZS5JTO1czBXH","colab_type":"code","outputId":"61a52eb2-12df-4f5a-a17c-2b3be630ea3e","executionInfo":{"status":"ok","timestamp":1585424779432,"user_tz":240,"elapsed":23600,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["gpt2.mount_gdrive()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Crc6Wbnc83F1","colab_type":"text"},"source":["# Import and Load Trained Model"]},{"cell_type":"code","metadata":{"id":"LWb7U9MU85yW","colab_type":"code","outputId":"15305a6d-217b-40f4-9c3b-6f613bf2a33e","executionInfo":{"status":"ok","timestamp":1585424801895,"user_tz":240,"elapsed":46024,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Copy checkpoint\n","gpt2.copy_checkpoint_from_gdrive(run_name='run1')\n","\n","# Start session and load model\n","sess = gpt2.start_tf_sess()\n","gpt2.load_gpt2(sess, run_name='run1', multi_gpu=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/run1/model-1000\n","INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ckVfupYwv4fr","colab_type":"code","colab":{}},"source":["def create_chat_outputs(prompts_list, num_responses = 100,moving_window=3, min_len_response=15, remove_responses=False, num_samples = 1):\n","\n","  # Initialize an emtpy list for the future addition of dataframes.\n","  df_list = []\n","\n","  # Iteratively enter each prompt until num_responses are produced by the nlp model. \n","  for prompt in tqdm(prompts_list):\n","\n","    notebook_directory = os.getcwd()\n","    path = '/content/drive/My Drive/5_datascience/2_context_chatbot/ouputs'\n","    extension = 'csv'\n","    os.chdir(path)\n","    csv_names = glob.glob('*.{}'.format(extension))\n","    os.chdir(notebook_directory)\n","    num_complete = len(csv_names)\n","\n","    print(prompt)\n","    output_dict = {}\n","\n","    # initialize inputs and chatbot reponses\n","    input_text = \"\"\n","    chatbot_response = \"\"\n","    oldtext=\"\"\n","    temp=.4 # what does temp do?\n","    moving_window_used = False\n","    output_list = []\n","    temp_list = []\n","\n","    i=1\n","    input_text = \"Client: \" + prompt + \"\\nTHERAPIST\"\n","\n","    \n","    \n","    prev_output_size = 0\n","\n","    # Generate text from the combined input text\n","    while(len(output_list) < num_responses):\n","      generated_texts = gpt2.generate(sess,\n","                  length=120,\n","                  temperature=temp,\n","                  prefix=input_text,\n","                  nsamples=num_responses - len(output_list),\n","                  batch_size=1,\n","                  return_as_list=True\n","                  )\n","      \n","       \n","\n","      # Determine where to split the response single text by checking if moving window is being used.\n","      if moving_window_used:\n","        split_index = moving_window \n","      else:\n","        split_index = i\n","\n","      responses = []\n","\n","      # check if the outputs meet the requirements. \n","      for k in range(len(generated_texts)):\n","        sample_response = generated_texts[k].split(\"THERAPIST:\")[split_index].split(\"CLIENT:\")[0].strip()\n","        if len(sample_response) > 1 and len(output_list) < num_responses:\n","          output_list.append(sample_response)\n","      \n","      output_set = set(output_list)\n","      output_list = list(output_set)\n","\n","      for l in range(len(output_list) - prev_output_size):\n","        temp_list.append(temp)\n","\n","      prev_output_size = len(output_list)\n","      temp += .05 # randomness parameter\n","\n","      print(f'For prompt number {len(df_list)}, {len(output_list)} outputs were created.')\n","\n","    output_dict['input'] = prompt\n","    output_dict['output_list'] = output_list\n","    output_dict['temp_list'] = temp_list\n","\n","    single_output_df = pd.DataFrame(output_dict)\n","    single_output_df.to_csv(f\"/content/drive/My Drive/5_datascience/2_context_chatbot/ouputs/prompt{num_complete}_output.csv\")\n","    df_list.append(single_output_df)\n","\n","\n","  return(df_list)\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fk9CJE_LcBY6","colab_type":"code","colab":{}},"source":["all_prompts = pd.read_csv('/content/drive/My Drive/5_datascience/2_context_chatbot/sample_prompts.csv')\n","notebook_directory = os.getcwd()\n","path = '/content/drive/My Drive/5_datascience/2_context_chatbot/ouputs'\n","extension = 'csv'\n","os.chdir(path)\n","csv_names = glob.glob('*.{}'.format(extension))\n","os.chdir(notebook_directory)\n","num_complete = len(csv_names)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uy4hQhc-rq9g","colab_type":"code","outputId":"198841b6-c3a8-4bdc-f3cb-07cf5e798173","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1585425385974,"user_tz":240,"elapsed":629998,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}}},"source":["all_outputs = create_chat_outputs(all_prompts['Prompt'][num_complete:])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["I can't get excited about anything \n","For prompt number 0, 55 outputs were created.\n","For prompt number 0, 73 outputs were created.\n","For prompt number 0, 82 outputs were created.\n","For prompt number 0, 94 outputs were created.\n","For prompt number 0, 97 outputs were created.\n","For prompt number 0, 98 outputs were created.\n","For prompt number 0, 99 outputs were created.\n","For prompt number 0, 99 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 1/2 [04:45<04:45, 285.66s/it]"],"name":"stderr"},{"output_type":"stream","text":["For prompt number 0, 100 outputs were created.\n","I don't feel anything \n","For prompt number 1, 48 outputs were created.\n","For prompt number 1, 71 outputs were created.\n","For prompt number 1, 86 outputs were created.\n","For prompt number 1, 90 outputs were created.\n","For prompt number 1, 95 outputs were created.\n","For prompt number 1, 99 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2/2 [09:42<00:00, 291.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["For prompt number 1, 100 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3Cck7AVJwvBX","colab_type":"text"},"source":["# Merge the outputs into a single csv"]},{"cell_type":"code","metadata":{"id":"SsPAEhbawuLT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4e60dbdf-60bb-49bc-b742-737f0b52b37e","executionInfo":{"status":"ok","timestamp":1585426376460,"user_tz":240,"elapsed":49104,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}}},"source":["notebook_directory = os.getcwd()\n","path = '/content/drive/My Drive/5_datascience/2_context_chatbot/ouputs'\n","extension = 'csv'\n","os.chdir(path)\n","csv_names = glob.glob('*.{}'.format(extension))\n","os.chdir(notebook_directory)\n","num_complete = len(csv_names)\n","\n","outputs_list = []\n","for csv_name in tqdm(csv_names):\n","    df = pd.read_csv(path+'/'+csv_name, low_memory=False)\n","    outputs_list.append(df)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n"," 24%|██▍       | 31/129 [00:00<00:00, 307.27it/s]\u001b[A\n"," 39%|███▉      | 50/129 [00:00<00:01, 74.74it/s] \u001b[A\n"," 45%|████▍     | 58/129 [00:06<00:16,  4.35it/s]\u001b[A\n"," 50%|████▉     | 64/129 [00:11<00:26,  2.45it/s]\u001b[A\n"," 53%|█████▎    | 68/129 [00:13<00:26,  2.27it/s]\u001b[A\n"," 55%|█████▌    | 71/129 [00:15<00:27,  2.12it/s]\u001b[A\n"," 57%|█████▋    | 73/129 [00:16<00:28,  1.97it/s]\u001b[A\n"," 58%|█████▊    | 75/129 [00:17<00:26,  2.05it/s]\u001b[A\n"," 60%|█████▉    | 77/129 [00:18<00:24,  2.11it/s]\u001b[A\n"," 60%|██████    | 78/129 [00:18<00:26,  1.91it/s]\u001b[A\n"," 61%|██████    | 79/129 [00:19<00:24,  2.05it/s]\u001b[A\n"," 62%|██████▏   | 80/129 [00:19<00:21,  2.28it/s]\u001b[A\n"," 63%|██████▎   | 81/129 [00:20<00:24,  1.98it/s]\u001b[A\n"," 64%|██████▎   | 82/129 [00:20<00:25,  1.82it/s]\u001b[A\n"," 64%|██████▍   | 83/129 [00:21<00:27,  1.68it/s]\u001b[A\n"," 65%|██████▌   | 84/129 [00:22<00:26,  1.68it/s]\u001b[A\n"," 66%|██████▌   | 85/129 [00:22<00:25,  1.70it/s]\u001b[A\n"," 67%|██████▋   | 86/129 [00:23<00:26,  1.64it/s]\u001b[A\n"," 67%|██████▋   | 87/129 [00:24<00:26,  1.60it/s]\u001b[A\n"," 68%|██████▊   | 88/129 [00:24<00:23,  1.73it/s]\u001b[A\n"," 69%|██████▉   | 89/129 [00:25<00:20,  1.91it/s]\u001b[A\n"," 70%|██████▉   | 90/129 [00:25<00:21,  1.84it/s]\u001b[A\n"," 71%|███████   | 91/129 [00:26<00:20,  1.85it/s]\u001b[A\n"," 71%|███████▏  | 92/129 [00:26<00:19,  1.88it/s]\u001b[A\n"," 72%|███████▏  | 93/129 [00:26<00:16,  2.16it/s]\u001b[A\n"," 73%|███████▎  | 94/129 [00:27<00:17,  2.01it/s]\u001b[A\n"," 74%|███████▎  | 95/129 [00:27<00:16,  2.09it/s]\u001b[A\n"," 74%|███████▍  | 96/129 [00:28<00:17,  1.86it/s]\u001b[A\n"," 75%|███████▌  | 97/129 [00:29<00:20,  1.59it/s]\u001b[A\n"," 76%|███████▌  | 98/129 [00:30<00:20,  1.52it/s]\u001b[A\n"," 77%|███████▋  | 99/129 [00:30<00:19,  1.55it/s]\u001b[A\n"," 78%|███████▊  | 100/129 [00:31<00:15,  1.82it/s]\u001b[A\n"," 78%|███████▊  | 101/129 [00:31<00:15,  1.81it/s]\u001b[A\n"," 79%|███████▉  | 102/129 [00:32<00:16,  1.68it/s]\u001b[A\n"," 80%|███████▉  | 103/129 [00:33<00:16,  1.59it/s]\u001b[A\n"," 81%|████████  | 104/129 [00:33<00:16,  1.51it/s]\u001b[A\n"," 81%|████████▏ | 105/129 [00:34<00:13,  1.78it/s]\u001b[A\n"," 82%|████████▏ | 106/129 [00:34<00:12,  1.83it/s]\u001b[A\n"," 83%|████████▎ | 107/129 [00:35<00:11,  1.94it/s]\u001b[A\n"," 84%|████████▎ | 108/129 [00:35<00:12,  1.74it/s]\u001b[A\n"," 84%|████████▍ | 109/129 [00:36<00:12,  1.61it/s]\u001b[A\n"," 85%|████████▌ | 110/129 [00:37<00:12,  1.55it/s]\u001b[A\n"," 86%|████████▌ | 111/129 [00:37<00:10,  1.65it/s]\u001b[A\n"," 87%|████████▋ | 112/129 [00:38<00:10,  1.57it/s]\u001b[A\n"," 88%|████████▊ | 113/129 [00:39<00:10,  1.56it/s]\u001b[A\n"," 88%|████████▊ | 114/129 [00:39<00:09,  1.54it/s]\u001b[A\n"," 89%|████████▉ | 115/129 [00:40<00:08,  1.62it/s]\u001b[A\n"," 90%|████████▉ | 116/129 [00:40<00:07,  1.72it/s]\u001b[A\n"," 91%|█████████ | 117/129 [00:41<00:07,  1.56it/s]\u001b[A\n"," 91%|█████████▏| 118/129 [00:42<00:07,  1.51it/s]\u001b[A\n"," 92%|█████████▏| 119/129 [00:43<00:06,  1.45it/s]\u001b[A\n"," 93%|█████████▎| 120/129 [00:43<00:06,  1.42it/s]\u001b[A\n"," 94%|█████████▍| 121/129 [00:44<00:05,  1.40it/s]\u001b[A\n"," 95%|█████████▍| 122/129 [00:45<00:05,  1.31it/s]\u001b[A\n"," 95%|█████████▌| 123/129 [00:45<00:04,  1.48it/s]\u001b[A\n"," 96%|█████████▌| 124/129 [00:46<00:03,  1.55it/s]\u001b[A\n"," 97%|█████████▋| 125/129 [00:47<00:02,  1.46it/s]\u001b[A\n"," 98%|█████████▊| 126/129 [00:48<00:02,  1.42it/s]\u001b[A\n","100%|██████████| 129/129 [00:48<00:00,  2.65it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TVNiyZewxKQE","colab_type":"code","colab":{}},"source":["all_outputs = pd.concat(outputs_list)\n","\n","all_outputs.to_csv('/content/drive/My Drive/5_datascience/2_context_chatbot/ouputs/all_outputs.csv', index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxRXrCHgx3VV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}