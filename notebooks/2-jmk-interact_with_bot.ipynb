{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-jcb-interact_with_bot","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPmjExV8bc0aB/tqcy/fsmC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ww8S1B9B88Ba","colab_type":"text"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"pZGa-D528t-s","colab_type":"code","outputId":"02adbfb6-4974-4127-85bb-4b90de714df1","executionInfo":{"status":"ok","timestamp":1587142957600,"user_tz":240,"elapsed":23695,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":675}},"source":["%tensorflow_version 1.x\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files\n","from google.colab import drive\n","from collections import Counter\n","import os\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","!python -m spacy download en\n","import spacy\n","nlp = spacy.load('en')\n","spacy.prefer_gpu()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"HprB-pM-9iAK","colab_type":"text"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"1YABMnvF9rij","colab_type":"code","outputId":"67ee3004-c073-4d4c-c28c-38a855073193","executionInfo":{"status":"ok","timestamp":1585252973100,"user_tz":240,"elapsed":4288,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Mount drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Crc6Wbnc83F1","colab_type":"text"},"source":["# Import and Load Trained Model"]},{"cell_type":"code","metadata":{"id":"LWb7U9MU85yW","colab_type":"code","outputId":"63e76c5f-37b9-4bf8-ffec-cbd9d6b60405","executionInfo":{"status":"ok","timestamp":1585252993567,"user_tz":240,"elapsed":16954,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# Copy checkpoint\n","gpt2.copy_checkpoint_from_gdrive(run_name='run1')\n","\n","# Start session and load model\n","sess = gpt2.start_tf_sess()\n","gpt2.load_gpt2(sess, run_name='run1', multi_gpu=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/run1/model-1000\n","INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"60uzd0PrAK06","colab_type":"text"},"source":["# Interact with the bot!"]},{"cell_type":"code","metadata":{"id":"2MaddMmo88pd","colab_type":"code","colab":{}},"source":["def interact_with_bot(moving_window=3, min_len_response=15, remove_responses=False, num_samples = 1):\n","  # initialize inputs and chatbot reponses\n","  input_text = \"\"\n","  chatbot_response = \"\"\n","  i=0\n","  oldtext=\"\"\n","  temp=.8 # what does temp do?\n","  moving_window_used = False\n","\n","  # Initialize lists to store the prompts and responses.\n","  client_prompts = list()\n","  therapist_responses = list()\n","  while input_text!=\"ABORT\":\n","    i=i+1\n","    if i==1:\n","      print(\"Can you tell me what you want to talk about today? It helps if you say at least a few sentences for context.\")\n","    input_text = input(\"\\n\")\n","    client_prompts.append(input_text) # adds the user input to prompts list\n","\n","    if input_text==\"ABORT\":\n","      break\n","    \n","    if(remove_responses == False):\n","      # Filter the input text so that it fits into the moving window\n","      if(len(client_prompts) <= moving_window):\n","        combined_text = \"\"\n","        for j in range(len(client_prompts)):\n","          if j != 0:\n","            combined_text = combined_text + therapist_responses[j - 1]\n","\n","          combined_text = combined_text + \"CLIENT: \" + client_prompts[j] + \"\\nTHERAPIST:\" \n","      else: \n","        moving_window_used = True\n","        combined_text = \"\"\n","        prompts_subset = client_prompts[-moving_window:]\n","        responses_subset = therapist_responses[-moving_window + 1:]\n","\n","        for j in range(len(prompts_subset)):\n","          if j != 0:\n","            combined_text = combined_text + responses_subset[j - 1]\n","          combined_text = combined_text + \"CLIENT: \" + prompts_subset[j] + \"\\nTHERAPIST:\" \n","\n","    else: \n","      combined_text = \"Client: \" + ' '.join(client_prompts[-moving_window:])\n","\n","    print(f'Input text: {combined_text}')\n","\n","    # Generate text from the combined input text\n","    single_text=gpt2.generate(sess,\n","                length=120,\n","                temperature=temp,\n","                prefix=combined_text,\n","                nsamples=num_samples,\n","                batch_size=1,\n","                return_as_list=True\n","                )\n","\n","    # Determine where to split the response single text by checking if moving window is being used.\n","    if moving_window_used:\n","      split_index = moving_window \n","    else:\n","      split_index = i \n","\n","    # Iteratively generate text until the response is greater than min_len_response \n","    temp=.4\n","    while(len(single_text[0].split(\"THERAPIST:\")[split_index].split(\"CLIENT:\")[0])<min_len_response):\n","      temp=temp+.05\n","      single_text=gpt2.generate(sess,\n","                length=120,\n","                temperature=temp,\n","                prefix=combined_text,\n","                nsamples=num_samples,\n","                batch_size=1,\n","                return_as_list=True\n","                )\n","  \n","    responses = []\n","    responses_scores = []\n","    for k in range(len(single_text)):\n","      sample_response = single_text[k].split(\"THERAPIST:\")[split_index].split(\"CLIENT:\")[0]\n","      sample_score = calc_seance_score(sample_response)\n","\n","      responses.append(sample_response)\n","      responses_scores.append(sample_score)\n","\n","      print(f'sample response: {sample_response}')\n","      print(f'seance score: {sample_score}')\n","    \n","    response = single_text[0].split(\"THERAPIST:\")[split_index].split(\"CLIENT:\")[0]\n","    therapist_responses.append(response) \n","    \n","    print(\"\\nTherapist Bot:\"+ response) #change 1 to i if the prior is re-insurted "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6Kt2FULRA-W","colab_type":"code","outputId":"9933d380-63b5-4036-cca9-40d168a8e9b2","executionInfo":{"status":"ok","timestamp":1587142923305,"user_tz":240,"elapsed":1550,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_scores = [3,4,4]\n","print(test_scores.index(max(test_scores))) # change the scoring mechanism for time (heavily penalize week)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p5BnWeNhATTo","colab_type":"code","outputId":"5658f72d-ad8f-4667-b747-134bea0f887e","executionInfo":{"status":"error","timestamp":1587142929514,"user_tz":240,"elapsed":7696,"user":{"displayName":"Jason Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiK8IafaB0Bu0wQRn-pJyDgCzHNv6GObP38rUvzzXc=s64","userId":"07126822508397489067"}},"colab":{"base_uri":"https://localhost:8080/","height":367}},"source":["interact_with_bot(moving_window=3, min_len_response=16, remove_responses=True, num_samples = 20)  # insert max response length? # discard all therapy responses # merge  # add in all the potential resonses until the number of samples is set. # closest to client response (improves synchrony)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Can you tell me what you want to talk about today? It helps if you say at least a few sentences for context.\n","\n","Hello I am feeling tired.\n","Input text: Client: Hello I am feeling tired.\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b795cdfc3935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteract_with_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_len_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_responses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# insert max response length? # discard all therapy responses # merge  # add in all the potential resonses until the number of samples is set. # closest to client response (improves synchrony)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-360ddc501147>\u001b[0m in \u001b[0;36minteract_with_bot\u001b[0;34m(moving_window, min_len_response, remove_responses, num_samples)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Generate text from the combined input text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     single_text=gpt2.generate(sess,\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'gpt2' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ckVfupYwv4fr","colab_type":"code","colab":{}},"source":["def create_chat_outputs(prompts_list, num_responses = 100,moving_window=3, min_len_response=15, remove_responses=False, num_samples = 1):\n","\n","  # Initialize an emtpy list for the future addition of dataframes.\n","  df_list = []\n","\n","  # Iteratively enter each prompt until num_responses are produced by the nlp model. \n","  for prompt in tqdm(prompts_list):\n","    print(prompt)\n","    output_dict = {}\n","\n","    # initialize inputs and chatbot reponses\n","    input_text = \"\"\n","    chatbot_response = \"\"\n","    oldtext=\"\"\n","    temp=.4 # what does temp do?\n","    moving_window_used = False\n","    output_list = []\n","\n","    i=1\n","    input_text = \"Client: \" + prompt + \"\\nTHERAPIST\"\n","    \n","\n","    # Generate text from the combined input text\n","    while(len(output_list) < num_responses):\n","      output_dict['temp'] = temp\n","      generated_texts = gpt2.generate(sess,\n","                  length=120,\n","                  temperature=temp,\n","                  prefix=input_text,\n","                  nsamples=num_responses - len(output_list),\n","                  batch_size=1,\n","                  return_as_list=True\n","                  )\n","      \n","      temp += .05 # randomness parameter \n","\n","      # Determine where to split the response single text by checking if moving window is being used.\n","      if moving_window_used:\n","        split_index = moving_window \n","      else:\n","        split_index = i\n","\n","      responses = []\n","\n","      # check if the outputs meet the requirements. \n","      for k in range(len(generated_texts)):\n","        sample_response = generated_texts[k].split(\"THERAPIST:\")[split_index].split(\"CLIENT:\")[0].strip()\n","        if len(sample_response) > 1 and len(output_list) < num_responses:\n","          output_list.append(sample_response)\n","      \n","      output_set = set(output_list)\n","      output_list = list(output_set)\n","\n","      print(f'For prompt number {len(df_list)}, {len(output_list)} outputs were created.')\n","\n","    output_dict['input'] = prompt\n","    output_dict['output_list'] = output_list\n","\n","    single_output_df = pd.DataFrame(output_dict)\n","    single_output_df.to_csv(f\"drive/My Drive/5_datascience/2_context_chatbot/ouputs/prompt{len(df_list)}_output.csv\")\n","    df_list.append(single_output_df)\n","\n","\n","  return(df_list)\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fk9CJE_LcBY6","colab_type":"code","colab":{}},"source":["all_prompts = pd.read_csv('drive/My Drive/5_datascience/2_context_chatbot/sample_prompts.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uy4hQhc-rq9g","colab_type":"code","outputId":"73758bfd-9271-4043-b13a-2ba328541f05","colab":{"base_uri":"https://localhost:8080/","height":944}},"source":["all_outputs = create_chat_outputs(all_prompts['Prompt'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/129 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["I suffer from debilitating social anxiety, which prevents me from having normal relationships. My negative thought is I will be alone forever.\n","For this prompt number 0, 43 outputs were created.\n","For this prompt number 0, 60 outputs were created.\n","For this prompt number 0, 79 outputs were created.\n","For this prompt number 0, 88 outputs were created.\n","For this prompt number 0, 93 outputs were created.\n","For this prompt number 0, 97 outputs were created.\n","For this prompt number 0, 99 outputs were created.\n","For this prompt number 0, 99 outputs were created.\n","For this prompt number 0, 99 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  1%|          | 1/129 [04:22<9:20:53, 262.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 0, 100 outputs were created.\n","I'm freaking out studying for finals\n","For this prompt number 1, 20 outputs were created.\n","For this prompt number 1, 36 outputs were created.\n","For this prompt number 1, 51 outputs were created.\n","For this prompt number 1, 60 outputs were created.\n","For this prompt number 1, 70 outputs were created.\n","For this prompt number 1, 80 outputs were created.\n","For this prompt number 1, 87 outputs were created.\n","For this prompt number 1, 90 outputs were created.\n","For this prompt number 1, 95 outputs were created.\n","For this prompt number 1, 99 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|▏         | 2/129 [11:36<11:04:39, 314.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 1, 100 outputs were created.\n","I'd like to feel more confident and less anxious\n","For this prompt number 2, 54 outputs were created.\n","For this prompt number 2, 72 outputs were created.\n","For this prompt number 2, 88 outputs were created.\n","For this prompt number 2, 92 outputs were created.\n","For this prompt number 2, 96 outputs were created.\n","For this prompt number 2, 98 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|▏         | 3/129 [15:29<10:08:50, 289.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 2, 100 outputs were created.\n","I'm anxious about my presentation, I think I will mess up\n","For this prompt number 3, 65 outputs were created.\n","For this prompt number 3, 87 outputs were created.\n","For this prompt number 3, 98 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  3%|▎         | 4/129 [18:19<8:49:03, 253.95s/it] "],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 3, 100 outputs were created.\n","I'm really overloaded with work and have a ton to do for tomorrow.\n","For this prompt number 4, 39 outputs were created.\n","For this prompt number 4, 58 outputs were created.\n","For this prompt number 4, 75 outputs were created.\n","For this prompt number 4, 84 outputs were created.\n","For this prompt number 4, 91 outputs were created.\n","For this prompt number 4, 96 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|▍         | 5/129 [23:18<9:12:19, 267.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 4, 100 outputs were created.\n","I'm feeling really stressed out all the time and I feel overwhelmed.\n","For this prompt number 5, 29 outputs were created.\n","For this prompt number 5, 46 outputs were created.\n","For this prompt number 5, 72 outputs were created.\n","For this prompt number 5, 81 outputs were created.\n","For this prompt number 5, 90 outputs were created.\n","For this prompt number 5, 96 outputs were created.\n","For this prompt number 5, 99 outputs were created.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  5%|▍         | 6/129 [29:06<9:57:31, 291.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["For this prompt number 5, 100 outputs were created.\n","I feel anxious\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cY0Vrko3sdi9","colab_type":"code","colab":{}},"source":["test_output[0].to_csv('test.csv')"],"execution_count":0,"outputs":[]}]}